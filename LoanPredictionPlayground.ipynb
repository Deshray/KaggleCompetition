{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91722,"databundleVersionId":14262372,"sourceType":"competition"}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-18T00:20:58.933281Z","iopub.execute_input":"2025-11-18T00:20:58.934958Z","iopub.status.idle":"2025-11-18T00:20:59.357008Z","shell.execute_reply.started":"2025-11-18T00:20:58.934891Z","shell.execute_reply":"2025-11-18T00:20:59.355827Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/playground-series-s5e11/sample_submission.csv\n/kaggle/input/playground-series-s5e11/train.csv\n/kaggle/input/playground-series-s5e11/test.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport gc\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom xgboost import XGBClassifier\nimport xgboost as xgb\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# --- Load Data ---\ntrain = pd.read_csv('/kaggle/input/playground-series-s5e11/train.csv')\ntest = pd.read_csv('/kaggle/input/playground-series-s5e11/test.csv')\nsample = pd.read_csv('/kaggle/input/playground-series-s5e11/sample_submission.csv')\n\ntry:\n    orig = pd.read_csv('/kaggle/input/loan-prediction-dataset-2025/loan_dataset_20000.csv')\n    print(f\"Original dataset loaded: {orig.shape}\")\n    use_orig = True\nexcept:\n    print(\"Original dataset not found, proceeding without it\")\n    use_orig = False\n\nprint(f\"Train: {train.shape} | Test: {test.shape}\")\n\ntarget = 'loan_paid_back'\nid_col = 'id'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T00:20:59.359063Z","iopub.execute_input":"2025-11-18T00:20:59.360076Z","iopub.status.idle":"2025-11-18T00:21:11.484352Z","shell.execute_reply.started":"2025-11-18T00:20:59.360042Z","shell.execute_reply":"2025-11-18T00:21:11.483224Z"}},"outputs":[{"name":"stdout","text":"Original dataset not found, proceeding without it\nTrain: (593994, 13) | Test: (254569, 12)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"def create_features(df):\n    \"\"\"Comprehensive feature engineering without target leakage\"\"\"\n    \n    # Extract grade components\n    df['grade_letter'] = df['grade_subgrade'].str[0]\n    df['subgrade_number'] = df['grade_subgrade'].str[1:].astype(int)\n    \n    # Grade mapping\n    grade_weight = {'A': 7, 'B': 6, 'C': 5, 'D': 4, 'E': 3, 'F': 2, 'G': 1}\n    df['grade_numeric'] = df['grade_letter'].map(grade_weight)\n    df['grade_score'] = df['grade_numeric'] * 10 + df['subgrade_number']\n    \n    # Financial ratios (core risk indicators)\n    df['income_loan_ratio'] = df['annual_income'] / (df['loan_amount'] + 1)\n    df['credit_income_ratio'] = df['credit_score'] / (df['annual_income'] / 10000 + 1)\n    df['monthly_income'] = df['annual_income'] / 12\n    df['debt_payment'] = df['monthly_income'] * df['debt_to_income_ratio']\n    df['disposable_income'] = df['monthly_income'] - df['debt_payment']\n    df['monthly_payment_est'] = (df['loan_amount'] * df['interest_rate'] / 1200) / (df['monthly_income'] + 1)\n    \n    # Risk metrics\n    df['risk_score'] = (df['debt_to_income_ratio'] * 0.4 + \n                        (850 - df['credit_score']) / 850 * 0.3 + \n                        df['interest_rate'] / 30 * 0.3)\n    df['credit_per_income'] = df['credit_score'] / (df['annual_income'] / 50000)\n    df['debt_burden'] = df['debt_to_income_ratio'] * df['loan_amount']\n    \n    # Log transformations (handle skewness)\n    df['log_income'] = np.log1p(df['annual_income'])\n    df['log_loan'] = np.log1p(df['loan_amount'])\n    df['log_credit'] = np.log1p(df['credit_score'])\n    \n    # Interaction terms\n    df['income_credit_interact'] = df['annual_income'] * df['credit_score'] / 1e8\n    df['loan_rate_interact'] = df['loan_amount'] * df['interest_rate'] / 1000\n    \n    # Binning (creates non-linear features)\n    df['credit_bin'] = pd.cut(df['credit_score'], bins=[0, 600, 700, 750, 800, 850], labels=False).fillna(0)\n    df['income_bin'] = pd.cut(df['annual_income'], bins=[0, 40000, 70000, 100000, 150000, np.inf], labels=False).fillna(0)\n    df['debt_bin'] = pd.cut(df['debt_to_income_ratio'], bins=[0, 0.2, 0.35, 0.5, 0.7, 1.0], labels=False).fillna(0)\n    # Quantile features for numerical columns\n    for col in ['annual_income', 'loan_amount', 'credit_score']:\n        for q in [5, 10]:\n            try:\n                df[f'{col}_qbin{q}'] = pd.qcut(df[col], q=q, labels=False, duplicates='drop').fillna(0)\n            except:\n                df[f'{col}_qbin{q}'] = 0\n    \n    return df\n\n# Apply feature engineering\ntrain = create_features(train)\ntest = create_features(test)\nif use_orig:\n    orig = create_features(orig)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T00:21:11.485397Z","iopub.execute_input":"2025-11-18T00:21:11.485853Z","iopub.status.idle":"2025-11-18T00:21:13.010698Z","shell.execute_reply.started":"2025-11-18T00:21:11.485828Z","shell.execute_reply":"2025-11-18T00:21:13.009250Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def target_encode_oof(train_df, test_df, cols, target_col, n_splits=10):\n    \"\"\"Out-of-fold target encoding to prevent leakage\"\"\"\n    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n    \n    for col in cols:\n        # OOF for train\n        train_encoded = np.zeros(len(train_df))\n        for tr_idx, val_idx in kf.split(train_df, train_df[target_col]):\n            mean_map = train_df.iloc[tr_idx].groupby(col)[target_col].mean()\n            train_encoded[val_idx] = train_df.iloc[val_idx][col].map(mean_map)\n        train_df[f'{col}_te'] = train_encoded\n        \n        # Global mean for test\n        global_mean = train_df.groupby(col)[target_col].mean()\n        test_df[f'{col}_te'] = test_df[col].map(global_mean).fillna(train_df[target_col].mean())\n    \n    return train_df, test_df\n\n# Categorical columns for encoding\ncat_cols = ['gender', 'marital_status', 'education_level', 'employment_status', \n            'loan_purpose', 'grade_subgrade', 'grade_letter']\n\ntrain, test = target_encode_oof(train, test, cat_cols, target, n_splits=10)\n\nfor col in cat_cols:\n    freq = train[col].value_counts(normalize=True)\n    train[f'{col}_freq'] = train[col].map(freq)\n    test[f'{col}_freq'] = test[col].map(freq).fillna(freq.mean())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T00:21:13.013404Z","iopub.execute_input":"2025-11-18T00:21:13.013834Z","iopub.status.idle":"2025-11-18T00:21:36.318919Z","shell.execute_reply.started":"2025-11-18T00:21:13.013806Z","shell.execute_reply":"2025-11-18T00:21:36.317846Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Define feature sets\nnumerical_base = ['annual_income', 'debt_to_income_ratio', 'credit_score', \n                  'loan_amount', 'interest_rate']\n\nengineered = ['income_loan_ratio', 'credit_income_ratio', 'monthly_income',\n              'debt_payment', 'disposable_income', 'monthly_payment_est',\n              'risk_score', 'credit_per_income', 'debt_burden',\n              'log_income', 'log_loan', 'log_credit',\n              'income_credit_interact', 'loan_rate_interact',\n              'grade_numeric', 'subgrade_number', 'grade_score',\n              'credit_bin', 'income_bin', 'debt_bin']\n\ntarget_encoded = [f'{col}_te' for col in cat_cols]\nfreq_encoded = [f'{col}_freq' for col in cat_cols]\n\n# Combine all features\nall_features = numerical_base + engineered + target_encoded + freq_encoded\n\n# Add quantile bins\nqbin_features = [col for col in train.columns if '_qbin' in col]\nall_features.extend(qbin_features)\n\n# Prepare X, y\nX = train[all_features].copy()\ny = train[target].values\nX_test = test[all_features].copy()\ntest_ids = test[id_col].copy()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T00:21:36.319868Z","iopub.execute_input":"2025-11-18T00:21:36.320116Z","iopub.status.idle":"2025-11-18T00:21:38.519987Z","shell.execute_reply.started":"2025-11-18T00:21:36.320096Z","shell.execute_reply":"2025-11-18T00:21:38.518964Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"N_FOLDS = 7\nSEED = 42\n\ncv = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n\n# Store OOF predictions and test predictions\noof_preds = np.zeros(len(X))\ntest_preds_xgb = np.zeros(len(X_test))\ntest_preds_lgb = np.zeros(len(X_test))\ntest_preds_cat = np.zeros(len(X_test))\n\nfold_scores = []\n\n# XGBoost parameters (optimized)\nxgb_params = {\n    'objective': 'binary:logistic',\n    'eval_metric': 'auc',\n    'learning_rate': 0.02,\n    'max_depth': 6,\n    'subsample': 0.8,\n    'colsample_bytree': 0.7,\n    'colsample_bylevel': 0.7,\n    'min_child_weight': 5,\n    'reg_lambda': 3.0,\n    'reg_alpha': 1.5,\n    'gamma': 0.5,\n    'tree_method': 'hist',\n    'random_state': SEED,\n    'n_estimators': 800\n}\n\n# LightGBM parameters\nlgb_params = {\n    'objective': 'binary',\n    'metric': 'auc',\n    'learning_rate': 0.02,\n    'num_leaves': 64,\n    'min_data_in_leaf': 100,\n    'feature_fraction': 0.8,\n    'bagging_fraction': 0.8,\n    'bagging_freq': 5,\n    'reg_lambda': 2.0,\n    'reg_alpha': 1.0,\n    'random_state': SEED,\n    'n_estimators': 800,\n    'verbose': -1\n}\n\n# CatBoost parameters\ncat_params = {\n    'iterations': 800,\n    'learning_rate': 0.02,\n    'depth': 6,\n    'l2_leaf_reg': 5,\n    'loss_function': 'Logloss',\n    'eval_metric': 'AUC',\n    'random_seed': SEED,\n    'verbose': False\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T00:21:38.520855Z","iopub.execute_input":"2025-11-18T00:21:38.521127Z","iopub.status.idle":"2025-11-18T00:21:38.530833Z","shell.execute_reply.started":"2025-11-18T00:21:38.521107Z","shell.execute_reply":"2025-11-18T00:21:38.529872Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n    print(f\"\\n*** Fold {fold}/{N_FOLDS} ***\")\n    \n    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n    y_train, y_val = y[train_idx], y[val_idx]\n    \n    # Add original data if available\n    if use_orig:\n        X_orig = orig[all_features]\n        y_orig = orig[target].values\n        X_train = pd.concat([X_train, X_orig], axis=0, ignore_index=True)\n        y_train = np.concatenate([y_train, y_orig])\n    \n    # XGBoost\n    xgb_model = XGBClassifier(**xgb_params)\n    xgb_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n    xgb_pred = xgb_model.predict_proba(X_val)[:, 1]\n    test_preds_xgb += xgb_model.predict_proba(X_test)[:, 1] / N_FOLDS\n    \n    # LightGBM\n    lgb_model = LGBMClassifier(**lgb_params)\n    lgb_model.fit(X_train, y_train, eval_set=[(X_val, y_val)])\n    lgb_pred = lgb_model.predict_proba(X_val)[:, 1]\n    test_preds_lgb += lgb_model.predict_proba(X_test)[:, 1] / N_FOLDS\n    \n    # CatBoost\n    cat_model = CatBoostClassifier(**cat_params)\n    cat_model.fit(X_train, y_train, eval_set=(X_val, y_val))\n    cat_pred = cat_model.predict_proba(X_val)[:, 1]\n    test_preds_cat += cat_model.predict_proba(X_test)[:, 1] / N_FOLDS\n    \n    # Ensemble OOF predictions (weighted average)\n    fold_pred = 0.4 * xgb_pred + 0.3 * lgb_pred + 0.3 * cat_pred\n    oof_preds[val_idx] = fold_pred\n    \n    fold_auc = roc_auc_score(y_val, fold_pred)\n    fold_scores.append(fold_auc)\n    print(f\"Fold {fold} AUC: {fold_auc:.5f} (XGB: {roc_auc_score(y_val, xgb_pred):.5f}, LGB: {roc_auc_score(y_val, lgb_pred):.5f}, CAT: {roc_auc_score(y_val, cat_pred):.5f})\")\n    \n    del X_train, X_val, y_train, y_val\n    gc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T00:21:38.531906Z","iopub.execute_input":"2025-11-18T00:21:38.532160Z","iopub.status.idle":"2025-11-18T00:53:05.469369Z","shell.execute_reply.started":"2025-11-18T00:21:38.532140Z","shell.execute_reply":"2025-11-18T00:53:05.468056Z"}},"outputs":[{"name":"stdout","text":"\n*** Fold 1/7 ***\nFold 1 AUC: 0.92148 (XGB: 0.92091, LGB: 0.92292, CAT: 0.91920)\n\n*** Fold 2/7 ***\nFold 2 AUC: 0.92034 (XGB: 0.91952, LGB: 0.92198, CAT: 0.91804)\n\n*** Fold 3/7 ***\nFold 3 AUC: 0.91996 (XGB: 0.91923, LGB: 0.92134, CAT: 0.91782)\n\n*** Fold 4/7 ***\nFold 4 AUC: 0.91896 (XGB: 0.91827, LGB: 0.92038, CAT: 0.91682)\n\n*** Fold 5/7 ***\nFold 5 AUC: 0.91841 (XGB: 0.91768, LGB: 0.91992, CAT: 0.91625)\n\n*** Fold 6/7 ***\nFold 6 AUC: 0.92044 (XGB: 0.91954, LGB: 0.92199, CAT: 0.91839)\n\n*** Fold 7/7 ***\nFold 7 AUC: 0.90837 (XGB: 0.88295, LGB: 0.92120, CAT: 0.91746)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"overall_auc = roc_auc_score(y, oof_preds)\nprint(f\"\\nOverall OOF AUC: {overall_auc:.5f}\")\nprint(f\"Mean Fold AUC: {np.mean(fold_scores):.5f} ± {np.std(fold_scores):.5f}\")\n\n# Ensemble test predictions (weighted average)\ntest_preds_final = 0.4 * test_preds_xgb + 0.3 * test_preds_lgb + 0.3 * test_preds_cat","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T00:53:05.470604Z","iopub.execute_input":"2025-11-18T00:53:05.470996Z","iopub.status.idle":"2025-11-18T00:53:05.775649Z","shell.execute_reply.started":"2025-11-18T00:53:05.470962Z","shell.execute_reply":"2025-11-18T00:53:05.774602Z"}},"outputs":[{"name":"stdout","text":"\nOverall OOF AUC: 0.91591\nMean Fold AUC: 0.91828 ± 0.00415\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# --- Predict on Test ---\nsubmission = pd.DataFrame({\n    'id': test_ids,\n    target: test_preds_final\n})\nsubmission.to_csv('submission.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T00:54:55.474931Z","iopub.execute_input":"2025-11-18T00:54:55.475282Z","iopub.status.idle":"2025-11-18T00:54:56.025333Z","shell.execute_reply.started":"2025-11-18T00:54:55.475258Z","shell.execute_reply":"2025-11-18T00:54:56.024082Z"}},"outputs":[],"execution_count":11}]}